# 데이터베이스를 지탱하는 기술


## 데이터베이스가 없으면 무엇이 곤란한가가?

### 기술자로서 요구되는 스킬

- 데이터베이스 기술의 중요성

- 이 책의 대상 독자

### 데이터베이스가 없으면 무엇이 곤란한가?

- 대량의 데이터 중에서 필요한 것을 빨리 반환할 수 없다

	- 데이터베이스가 없으면 뭐가 대안인가? 당연히 Excel이나, 데이터를 일렬로 정리하고 있는 파일이 될 것이다. 원하는 데이터를 찾고싶을 때, B+Tree Index, Hash Index 와 같은 알고리즘을 쓰지 않는 이상 평소의 우리라면 하나, 하나 모두 살펴볼 것이다. 그렇게 되면 데이터가 매우 많아졌을 때, 도저히 빠른 시간 내에 원하는 데이터를 반환할 수 없다. 

- 대량의 데이터를 메모리 내에서 만으로는 취급할 수 없다

	- 데이터베이스가 없다면, 두 번째 대안으로 어떻게 보면 메모리로 여길 수 있다. 하지만 메모리의 가장 중요한 속성은 빠르지만, 휘발성이라는 것이다. 그렇게 되면 데이터 복구가 쉽지 않다는 얘기가 된다. 또한 데이터가 많아질 때에 대한 생각을 꼭 해야 한다. 

- 장애가 발생했을 때 빠른 복구가 어렵다

	- 만약 Excel 파일이 삭제되거나, 데이터를 쌓고 있는 특정한 파일이 사라진다면 모든 게 끝나는 것이다. 데이터가 사라지게 된다는 건 매우 큰 장애 발생이다. 허나 데이터베이스는 어딘가에 장애가 나도, 데이터가 사라지는 현상은 없다. 데이터의 무결성 또한 발생하지 않을 수 있는데, 트랜젝션을 어떻게 관리했는지에 따라 발생이 덜하거나 많이하게 된다. 또한, 데이터베이스의 경우 백업과 같은 기능을 갖고 있기 때문에, 장애 대응이 ‘가능’한 것이 가장 중요한 요소라고 본다.

- 병렬성 제어가 어렵다

	- 똑같은 파일, 똑같은 레코드를 바꾸게 되면, 가장 최신으로 바꾼 사람의 결과만 남게 된다. 이게 바로 베타 제어의 한계성이다.   문제는, 동시성, 병렬성을 어떻게 해결할 것인가가 가장 관건이라고 생각한다. 동시성 문제를 해결하려면 결국 순차적으로 처리를 하게 되는데, 그러면 속도가 매우 저하될 수밖에 없다.  이 부분을 해결하는 것들은 데이터베이스가 해주지만, 어떻게 해줄지 향후 책에서 유심히 봐야할듯.

- 데이터 무결성을 보장하는 것은 어렵다

	- 데이터가 무결성을 보장하려면, 병렬성 제어가 확실해야 가능하다. 사실 둘이 굉장한 연관성을 갖고 있다. 데이터베이스가 있다면 데이터가 무결성을 갖게 될 수 있도록 해주는 기능이 트랜젝션일 것. 물론 다른 방법들이 있을텐데, 그런 것들은 또 찾아봐야지.  무결성을 갖을 필요 없는 데이터는 어떤 것일까?

### 이 책에서는 무엇을 다루어 나갈 것인가?

## 인덱스로 고속 액세스 실현하기

### ‘키와 값의 페어’를 관리하고 싶다

- 전체 검색은 대량의 데이터에 적합하지 않다

	- 한 마디로 ‘선형’ 검색은 맞지 않다. O(N) -> 데이터의 개수만큼 검색을 해야한다면, 절대로 scaling 이 불가능하다.

- 원하는 위치까지 순식간에 도달하는 방법 생각하기

	- 우선 원하는 위치로 순식간에 도달하려면, 해당 위치를 어떻게든 알고 있어야 한다. 인덱스를 알고 있다면, 그냥 그대로 가면 된다. 문제는, 위치가 고정되어야한다. 고정이 되면 어디로 바로 갈 수 있기 때문이다. 문제는 특정한 곳의 크기가 고정이 되면, 낭비되는 공간이 매우 커질 확률이 높기 때문에, 좋은 방법이라고는 볼 수 없다.

		- 레코드에 들어가 있는 데이터는 얼마나 큰지 작은지 모르기 때문에, 가변하면서도 빠르게 조회할 수 있는 방법이 필요하다.

- 인덱스 구조 도입하기

	- 인덱스를 색인이라고 번역이 되는군! 인덱스 구조를 넣게 되면, 어떤 번호가 어떤 데이터를 가리키고 있다는 파일이 만들어져서, 그것만 검색하면 된다. 이렇게 되면 굳이 데이터를 고정시킬 필요도 없고, 순차적으로 검색할 필요가 없어진다. 왜냐하면 바로 access 가 되니까!

		- 아래를 보니 ‘왜’ 바로 access 할 수 있는지 이해하게 됨.

	- [Why is an array index O(1)?](https://stackoverflow.com/questions/23103690/why-is-accessing-any-single-element-in-an-array-done-in-constant-time-o1)

		- An array starts at a specific memory address start. An element occupies a certain amount of bytes element_size. The array elements are located one after another in the memory from the start address on. So you can calculate the memory address of the element i with start + i * element_size. This computation is independent of the array size and is therefor O(1).

		- The key formula:  address + sizeOfElement * (index - 1) -> You know the start address. That means you can know the other following by. So you just ‘know’ instead of for looping!

- 해시 인덱스

	- Map 이랑 같은 구조라고 생각하면 되는데, HashMap 이 어떻게 구성이 되고, 어떻게 Hash 값을 계산한 후에 Index를 할 수 있는지 너무 궁금하다. Hash 를 계산하는 것 자체는 O(1)이 맞지만, 과연 Hash 를 계산한다고 해도, 어떤 값이랑 연결되어 있는지 알아야 한다. 그리고 정말 연결된 것이 맞는지까지 확인 작업을 해야하기 때문에, 그 원리가 궁금하다. 

	- 해시 인덱스가 물론, 모든걸 해결해주지는 않는다. 문자열 뭐랑 맞는거, 날짜 범위 검색, 아니면 정렬 관련 불러오는거는 모두 인덱스가 해결해줄 수 있는 부분들이 아니다. 인덱스가 가장 잘하는 것은, 색인이 등록된 데이터를 가장 빠르게 갖고오는 것이다.

### 인덱스의 기본 ‘B+Tree 인덱스’

- B+Tree 인덱스란?

	- 루트, 브랜치, 리프 형식으로 되어 있는 인덱스다. 데이터가 많으면 많을수록 층이 생기지만, 층 하나마다 엑세스 점 하나라고 생각하면 됩니다. 물론, 데이터가 매우 많이 생겨야 층이 더 커질거라 본다. 

		- Tree 라는 데이터 구조에 대해서 조금 더 알아야 할 것 같다. 탐색할 때 가장 많이 쓰이는 것 같은데, 어떻게 해야 알맞는 상황에 가장 빠르게 원하는 데이터를 갖고올 수 있게 되는지 봐야겠다.

- 다분기 트리와 이진 트리

	- 다분기 트리

		- 분기를 두 개 이상 하는 트리를 다분기 트리라고 하는데, 아무래도 층도 적당하게 만들고, 데이터도 적당하게 많이 저장하려면 분기를 여러 개 할수밖에 없다고 생각한다. 이같은 경우에는 n^m이 되는거지! O(lognm)

	- 이진 트리

		- 분기를 두 개만 한다는 것이라고 이해하면 된다. 그래서 이걸 이진 트리, Binary Tree 라고 부르는 듯 하다. 하지만 문제는 2^n에 한 번씩 계층이 생긴다는 것이다. 그래서 O(log2n)이 되는 것이다.

			- 계층의 개수에 있어서 한계가 있다. 많은 데이터를 저장할 수 없다. 이는 데이터 타입의 크기때문 아닐까라는 추측을 해본다.

- B+Tree와 B-Tree

	- +: 무조건 루트에서 리프까지 검색. 리프가 키값을 가지고 있음. -: 브랜치도 키값을 가지고 있어서, 위 브랜치로 다시 가야하는지, 아래 리프로 가야하는지에 대한 연산을 해야한다.  결론적으로, B+Tree 가 RDBMS 표준 인덱스 구조가 되었다.

### RDBMS에서는 어떻게 최적화를 실현하고 있는가?

- 고유성의 보장

	- 왜 고유성이 보장될까? 사실 인덱스는 단 하나의 값을 갖게 된다. 그래서 어느정도 보장이 된다고 생각할 수 있고, B+Tree 에서 해당 해시값이 단 하나의 리프만을 도달하게 된다. 이렇다면 고유성이 보장된다고 할 수 있지 않을까?

- 멀티 컬럼 인덱스

	- 인덱스는 한 컬럼만 걸 수 있는 게 아니다. 여러 컬럼을 걸 수 있다. 하지만, AND 조건 을 많이 거는 컬럼이라면, 둘 다 인덱스를 하는 게 맞다. 이유가 없다면, 모든 컬럼에 인덱스를 걸게 될 것이다.

- 인덱스만을 읽는 검색

	- Index Only Read, Covering Index로도 불린다. 인덱스만을 읽어서 검색하는 경우는 뭐가 있을까? 사실 COUNT(*) 함수, 인덱스가 걸린 특정 컬럼에 대한 aggregation 함수 외에는 없지 않을까 싶다. 조금 더 의문을 품어보면 더 나오지 않을까? 

		- 인덱스만을 읽는 검색이 지원이 안 되는 데이터베이스는 랜덤 엑세스를 하게 된다. 인덱스의 개수가 아닌, 데이터의 개수를 계속 왔다갔다 봐야하기 때문이다. 

- 인덱스 병합

	- 인덱스 병합과 멀티 컬럼 인덱스의 차이는 뭘까? OR연산을 할 경우에 쓴다고 얘기 나오지만 이해를 하지 못했다. 아무래도 찾아봐야할듯.

		- [http://use-the-index-luke.com/sql/where-clause/the-equals-operator/concatenated-keys](http://use-the-index-luke.com/sql/where-clause/the-equals-operator/concatenated-keys)

		- [https://stackoverflow.com/questions/179085/multiple-indexes-vs-multi-column-indexes/179109#179109](https://stackoverflow.com/questions/179085/multiple-indexes-vs-multi-column-indexes/179109#179109)

### 업데이트 비용 절감을 위한 노력

- 디스크에 모아서 기록하기

	- Random Write, Sequential Write.  아무래도 데이터를 쓰기할 때 업데이트 비용이 가장 크게 들거라 생각한다. 인덱스도 업데이트 해야한다! 그런데 이를 계속 DB Write 할때마다 나타난다면, 처리 속도가 느려질거라 생각한다. 이게 느려지지 않게 위해서 디스크에 모아서 한 방에 기록하는 기능을 만든 게 MySQL 의 InnoDB라고 알게 되었다.

		- InnoDB 에 대해서 조금 더 알아봐야겠다.

- 병렬 갱신 성능 높이기

	- 수많은 클라이언트들이 DB 를 치게 된다면, 동시성 처리가 어려워진다. 그래서 결국엔 DB 입장에서는 테이블에 락을 걸 수밖에 없게 된다. 데이터의 무결성을 유지하기 위함이다. 허나, 데이터의 무결성을 유지하면서도 동시성 처리력을 높여야 하는 게 우리의 일이다.

		- 그 방법으로 우선 B+Tree 의 Lock Free 알고리즘이 개발되어 가고 있고 (지금은 뭔지 궁금함), 사용자에게는 테이블에 하나로 보이지만 내부적으로는 테이블이 파티셔닝되는 기능이 또 있다고 한다. 이 기능에 대해서도 조금 더 알아봐야겠다.

## 테이블 설계와 릴레이션

### 데이터 모델링 기술의 중요성

- 애플리케이션의 모든 요구사항을 알고 데이터를 고정적으로 만드는 것은 쉽지 않다. 절대로 애플리케이션이 바뀌지 않을 것이라는 전제가 아닌 이상 … 그럴 일이 없기 때문에 우리는 확장성을 잘 고려한 데이터 모델링을 해야한다. 

	- 어떤 상황이 와도 전체적인 구조를 바꿀 필요 없게 만들어두어야 한다. 그 정도의 확장성을 고려하지 않는다면 정말 큰 고생을 하게 되고, 그 수많은 데이터 마이그레이션이라던지, 어마어마한 작업이 들어가게 된다.

### 예제를 사용하여 생각해 보자

- 데이터 항목과 관계성에 대한 의식

	- 데이터 모델링을 할 때, 항목과 관계성에 대해서 많이 생각해야 한다. 어떠한 데이터를 갖고 있어야 하는지, 그 데이터가 어떠한 속성을 갖는지, 다른 데이터와 특별한 관계성을 갖고 있는지, 기타 등등 많다. 

	- 중요한 것은 ‘일관성’을 갖는 것이다. 데이터 모델링 하는 것 자체도 일관성이 있어야 한다. 이럴 때에는 저렇게 하고, 저럴 때에는 저렇게 한다면, 관리 지점이 굉장히 늘어난다. 또한, 데이터를 파악하기 위해서 많은 공수가 들어간다.

- 전통적인 방법으로 테이블을 만들어보자

	- 전통적인 방식으로 데이터를 모델링한다면, 그냥 하나의 테이블에 다 때려넣게 되고, 무엇보다 데이터의 중복이 매우 발생한다. 

		- 이 문제를 관계를 통해서 해결을 하는 것 같은데, 내가 설계를 할 때는 ManyToMany의 폐해에 접어들게 된다. 결국엔 데이터가 계속 반복하게 된다면, ManyToMany가 맞는 것 같다 생각해서 다 그렇게 설계를 해버린다. 

### 포인트 1:’테이블 관계’를 도입

- 참조 무결성 제약

	- 관계성을 도입해야 데이터의 기본적인 중복을 없앨 수 있다. 하지만 PK는 꼭 설정해줘야한다. PK를 변경할 때는 꼭 주의를 기울여서 변경하자. 변경하게 되면 막대한 성능 저하를 겪을 수 있다. 이유는, 인덱스가 만들어져 있고, 데이터베이스 입장에서 바꿔야할 부분들이 한 두가지가 아니어서 그렇다. 

	- Referential Integrity(참조 무결성)이란, 데이터가 무결해야한다는 것이다. Orphan 데이터라던지, 특정한 데이터와의 참조가 잘못 되었다던지, 이러한 경우를 없애야 한다는 것이다. 그래서 DB 쪽에서도 확인을 하지만, 애플리케이션 단에서도 확인을 해야하는 부분이다. 애초부터 제대로 된 데이터를 패스하는 게 중요하다.

### 포인트 2: 테이블 설계의 타당성 검증하기

- 연속적인 번호의 열 도입하기

	- 1:N이 필요하게 된 계기가 바로 연속적으로 열을 도입할때다. 연속적으로 열을 도입하게 되면, NULLABLE 한 열들이 굉장히 많이 생성되게 되고, 무엇보다 공간 낭비가 심해진다. 물론 NoSQL이라면 다른 이야기다. 자유롭게 계속 컬럼을 왈가왈부할 수 있기 때문이다.

	- 또한, 열 추가 외에 Set 식으로 FK 부분에 넣을 수 있다. 하지만 많은 데이터베이스가 Set type 을 지원하지 않으며, 지원한다 해도 인덱싱을 하기가 쉽지 않다. 

- 1:N 관계를 두 개 도입하기

	- 1:N 관계를 만들어내려면, 매퍼 테이블을 만들어야 한다. 하지만 아까 설명했듯이, 매핑 테이블을 더 빨리 조회하기 위해서는, 인덱싱이 잘 되어 있어야 한다. 결국 메핑 테이블이 가장 많은 데이터를 갖게 될 것이고, 매핑 테이블을 계속 업데이트 하며 쓴다면, 조회하는 데 성능 저하가 분명히 올 것이다. 그래서 예를 든다면, 메핑 테이블에 조회 조건을 만든다. 특정한 기간동안 유효하다던지, 그런 식으로 하면 굳이 삭제를 할 필요 없고 계속 데이터를 저장만 하게 되고 굳이 PK를 수정하게 될 필요가 없어진다.

		- 데이터가 너무 많아지면 확실히 문제가 생긴다. 그래서 데이터를 여기 저기로 나눈다고 들었다. 이건 어떻게 해야 하는지 알아봐야 한다. 물론 샤딩이라는 개념이 여기에서 나올 듯 하다. 테이블 파티션 기타 등등 … 언제 꼭 찾아봐서 DB Scaling 에 대한 주제까지 공부해볼 계획이다.

		- 또한, PK를 변경했을 때 ‘정말로’ 어떻게 돌아가는지에 대한 궁금증이 생겼다. 책에서는 자세히 안 알려줬지만, DB 안에서는 어떻게 될지 한 번 생각해보자.

### 정규화 이론의 기본을 파악해 두자

- 제1규정형

- 제2규정형

- 제3규정형

- 정규형은 어디까지 이해해야 하는가?

	- 제3정규형 만으로 모든 것을 해결할 순 없다가 결론이다. 그러므로, 계속 데이터 모델링을 경험해야 한다. 많은 백엔드 애플리케이션을 만듦으로써, 데이터 모델링 실력을 쌓을 수 있다. 또한, 하다 보면, 데이터베이스 밴더에 맞게 데이터 모델링을 할 수 있게 되기도 한다. 매우 중요한 부분이라 생각한다. 

	- 제 1,2,3 정규형은, 이 책을 읽으면서 나왔던, 테이블 -> 관계 형성 -> PK 확실하게 만들기 정도로 볼 수 있다. 정규화 이론을 언제 공부해봤으면 좋겠다. 아무래도, 조금 더 대규모의 데이터를 다루는 어플리케이션이라면 꼭 공부할 기회가 올 거라 본다. 지금 단계에서는 그정도까지는 필요 없어 보이지만, 호기심이 말하고 있다. 

	- 참고로, 내가 공부했던 Database Design & Modeling Udemy 강좌에서 봤던 게 훨씬 더 잘 설명 되어 있다. 다시 복습해보자.

## SQL 문의 특징과 이를 잘 다루는 법

### 테이블 조작하기

- 테이블 작성하기

	- 테이블을 한 번 정의하게 되면 업데이트 하기 쉽지 않다. Migration 부터 시작해서, altering, 기타 등등 모두 쉽지 않다. 보통은 table의 구조를 변경하기 위해서는 해당 테이블의 모든 update를 막은 후에 구조를 변경한다. 

		- 요즘은 update를 막지 않고도 구조를 변경할 수 있는 방법이 많이 생긴다고는 한다. 이는 조사해야할 부분이다.

	- 공간에 대한 얘기가 나왔다. 물론 변경하기 쉽지 않다는 얘기와 함께 나오는 부분이다. 데이터 공간을 막 쓰게 되면, 테이블 용량이 무지막지하게 커지게 되어 결국엔 데이터를 줄이거나 샤딩해야 하는 상황이 온다. 이러한 일을 최소로 줄이기 위해서는, 필요에 맞는 공간을 잘 측정해서 처음부터 잘 정의해야한다. 

		- 물론, 공간의 측정이라던지 어떠한 데이터형을 사용할건지, 그 데이터형이 어떤 원리로 얼마나 공간을 차지하는지 잘 공부해야 한다. 내가 자주 쓰는 데이터베이스에 대해서 조사해봐야겠다. 

		- 참고로 데이터형을 ‘표준형’으로 맞추면 좋지 않다. 여기서 Context Dependent 하게 움직여야한다. MySQL, Oracle, Postgre, 각종 데이터베이스 vendor 에 맞게 조사해서 데이터형을 정의해야한다.

- INSERT 문/SELECT 문/UPDATE 문/DELETE 문을 사용하여 데이터 조작

	- MySQL의 벌크 INSERT문은 어떻게 동작할까?

		- LOAD문도 있다는데, 각종 데이터베이스 Vendor 에 맞는 데이터를 INSERT할 수 있는 특별한 명령문들이 있다. 뭐가 있는지 한 번 보는것도 좋을 듯 하다.

	- UPDATE문을 사용할 때는 보통, 먼저 조회하고 수정할 레코드가 있는지 없는지를 많이 따진다. 있으면 업데이트, 없으면 새로 만든다던지, 이런 다양한 처리 방법에 대해서 알고 있으면 좋을 듯 하다.

	- JOIN. 꽤 어려운 주제인 듯 하다. JOIN은 느리니 웬만하면 쓰지 마라, 하는 프로젝트도 있다고 한다. 사실 JOIN은 느린 게 아니라, 일반 개발자 입장에서 JOIN 쿼리를 빠르게 만드는 게 어렵기 때문이라고 한다. 

		- JOIN을 더 이상 쓰기 힘든 상황이 올 수 있다. 왜냐하면 특정 테이블이 굉장히 커지고 트래픽이 몰린다면, 샤딩(데이터를 여러 리모트에 테이블을 분산시키는 것)을 할수밖에 없다. 하지만 샤딩된 테이블에 JOIN을 한다면, 원하는 데이터를 못 가져올 수도 있다. 그래서 JOIN을 쓰고자 하는 테이블은 샤딩이 될 필요 없는 테이블, 트래픽이 그렇게 나오지 않을 테이블에 하는 것이 좋다고 생각한다. (물론 데이터가 계속 쌓이면 커지겠지만 … 하지만 그만큼 그 테이블에 액세스하는 게 많지 않다면 괜찮다고 본다.)

### SQL 문의 실행 효율 의식하기

- 적절한 인덱스가 사용되고 있는지 확인

	- 보통 EXPLAIN을 걸어서 뭐가 중요한지 볼 수 있다. 보통은 인덱스가 잘 걸리고 있는지, 또한 다른 지표들이 있는데, 그 지표들에 대해서 조금 더 공부해볼 필요가 있다. 

		- 어떠한 지표들이 있고, 각각 지표들이 무슨 의미를 갖고 있는지에 대해서 조사해보자.

- 관리계 명령

	- 특정 테이블이 얼마나 많이 바쁜지, 어떠한 쿼리가 가장 많이 쓰이는지와 같은, 데이터베이스의 안정성을 측정하는 SQL문들이 있다고 한다. Management Statements? 조사해보길 바란다.

### SQL의 장점과 단점

- SQL은 기술 습득이 용이하다

	- Vendor 마다 특정하게 중요한 SQL문들이 있는 듯 하다. 그런 것들에 대해서 조금 제대로 알고, SQL문들이 데이터베이스 상에서 어떻게 동작하는지 이해하고 있다면, SQL문을 업으로 삼을 수 있지 않을까도 싶다. 

- 기능면

	- Stored Procedure 얘기가 나왔는데, MySQL에서는 조금 빈약하지만, Oracle 같은 경우는 거의 프로그래밍 언어 수준이라고 한다. 물론 Stored Procedure를 사용하는 이유는 바로 Network 비용이 비쌌던 옛날 시대에 많이 썼다고 한다. Remote Networking 비용 없이 바로 데이터베이스 내부에서 특정한 Task를 처리할 수 있기 때문이다. 요즘 같은 경우는 로직은 프로그래밍 언어로, 데이터 입출력은 데이터베이스 SQL문으로만 처리하자는 문화가 잡혀가고 있다고 한다. 물론 아직도 쓰는 이유는, 정말로 많이 사용하는 ‘간단한’ 기능이 필요한 부분들만 Stored Procedure로 처리하고 있다고 한다.

## 가용성과 데이터의 복제

### 데이터베이스는 어떤 때에 크래쉬되는가?

- 전형적인 장애 시나리오

- 디스크 이중화로 데이터 손실 방지하기

### 복제

- 단방향 복제

- 양방향 복제

- 장애로부터의 복구 방법

- 인위적 실수에 대한 해결

- 백업을 복원한 후 어떻게 하면 좋은가?

- 고의로 지연시킨 복제

## 트랜잭션과 무결성, 무정지성

### 트랜잭션의 중요성 이해하기

- 어중간한 상태 방지하기

- SQL 문 레벨에서의 롤백

- 무정지성 확보하기

### 잠금 매커니즘에 의한 배타 제어

- 잠금의 범위

- 잠금 기간

### 복제 및 트랜잭션

- ‘원자성을 갖는 복재’의 중요성

- 사용자는 원자성이 있는 복제에 어떻게 대처하고 있는가?

## 스토리지 기술의 변천과 데이터베이스에 끼치는 영향

### 하드웨어 성능 개선의 역사

- HDD에 의한 처리의 한계

- 메모리 가격 하락에 따른 64비트 환경의 극대화

- 단일 스레드 처리의 성능 문제

- SATA SSD에 의한 성능 개선

- PCI-Express SSD의 효과

### 데이터베이스 개선의 역사

- CPU 확장성 향상

- 디스크 I/O 병렬성의 개선

- 백그라운드 처리의 분할/병렬화

### 향후 데이터베이스에 요구되는 것

- 네트워크 및 CPU의 이용 효율이 더 중요하게 된다

- 성능 이외의 중요성이 높아진다

## 데이터베이스 운용 기술의 급소

### 데이터베이스 운용의 어려움을 알자

### 문제 예방

- 잘 알고 있는 기술을 사용

- 입증된 기술을 사용

- 아키텍처를 복잡하게 하지 않기

### 문제 인지

- 모니터링해야 할 항목

### 문제 해결

- 성능 문제에 대한 대처

- ‘돌연사’에 대한 대처

## MySQL로 배우는 데이터베이스 관리

### MySQL 도입의 포인트

- MySQL 설치 및 기본 설정

- 스토리지 엔진

### MySQL 운용에 필요한 파일의 기초 지식

- 로그 파일 형식

- my.cnf의 설정 항목

### MySQL 백업의 기초

- 무엇을 위해 무엇을 백업할 것인가?

- 백업 유형

- 복구 방법

### MySQL에서의 백업/복구

- 콜드 백업의 절차

- 바이너리 로그에 의한 포인트 인 타임 복구

- mysqldump에 의한 온라인 백업

- LVM 스냅샷 기능을 통해 온라인 백업

## MySQL의 소스 코드를 추적해 보자

### 소스 코드를 아는 것이 의미가 있을까?

- 장애가 발생했을 때 원인을 찾을 수 있다

- 자신이 직접 버그를 수정할 수 있다

- 자신에게 필요한 기능을 구현할 수 있다

- MySQL의 소스 코드 입수하기

### 소스 코드의 구조를 보자

- sql

- include

- mysys

- storage

- strings

- mysql-test

- client

### 소스 코드를 분석해 보자

- 정적 분석 방법

- 동적 분석 방법과 MySQL의 빌드 방법

### MySQL의 설계 사상을 알아보자

- 플러그인화를 강력히 추진하고 있다

- 외부 라이브러리에는 최대한 의존하지 않는다

- 디버깅 기능

- 엔디안 프리

- 함수 포인터, 서브 클래스를 많이 사용하여 범용성을 높이기

- 플러그인 개발이란 무엇인가?

### 소스 해킹 사례 연구

- [사례1] 코어 파일에서 문제 부분 특정하기

- [사례2] 스택 트레이스로부터 문제 파악하기

- [사례3] 새로운 기능 추가해 보기

- 패치의 실행 예

### MySQL 개발 커뮤니티

- 버그 리포트

- WorkLog로 새로운 기능을 등록

- 패치 게시/리뷰/토론

## 데이터베이스 기술의 현재와 미래

### 데이터베이스 기술 동향

- 데이터 모델링 및 SQL

- 온라인에서의 정의 변경

- 스키마 없는 데이터베이스

### 대량의 데이터를 고속으로 처리하는 기술

- 인덱스 성능의 저하 요인

- 레인지 파티셔닝

- B+Tree 이외의 인덱스

- 고속의 SSD 이용

- 트랜잭션

### 분석계 처리 및 열 지향 데이터베이스

- 분석계 처리는 무엇이 어려운가?

- 기존 RDBMS에 있어서의 과제

- 열 지향 데이터베이스란 무엇인가?

- 열 지향 데이터베이스의 장점

- 열 지향 데이터베이스의 단점

### NoSQL 데이터베이스

- 메모리 안에서 처리가 낳은 새로운 과제

- SQL 데이터베이스의 과제

- NoSQL이란 무엇인가

- NoSQL은 테이블/파일을 연 채로 놔둔다

- 일반적인 NoSQL의 단점

- NoSQL의 용도

- RDBMS와 NoSQL의 하이브리드 구성

- 분산 데이터베이스

### 그 외의 주제

- Write Once의 데이터베이스

- Write Scaling

## 빅 데이터 시대의 데이터베이스 설계

### 웹 서비스를 위한 데이터베이스 개론

- 데이터베이스의 선정 기준

- 소셜 게임의 주요 특징

- 대규묘 웹 서비스용 데이터베이스에 요구되는 기능

- 규모가 다르면 선정 기준도 바뀐다

### Mobage에서의 데이터베이스 활용 사례

- 대규모 서비스 및 데이터베이스

- 클라우드와 실제 서버

- 데이터베이스 제품 선정

### 웹 서비스 및 데이터 모델링

- 데이터 모델링의 중요성을 알자

- 데이터 분류

- 테이블 관련

### 데이터 양 증가 대책과 고속화 수법

- 테이블 사이즈와 부하 대책

- DELETE의 튜닝

- UPDATE 주체의 테이블

- 부하 경향 모니터링하기

### MySQL의 성능 개선 테크닉

- 쿼리 개선하기

- 느린 트랜잭션 개선하기

- 경쟁에서의 배려

